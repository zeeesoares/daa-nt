{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c594261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.data_utils import load_datasets\n",
    "from utils.submission_utils import *\n",
    "import holidays\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "\n",
    "traffic_train = pd.read_csv(\"../../datasets/training_data.csv\", keep_default_na=False, encoding='latin1')\n",
    "traffic_test = pd.read_csv(\"../../datasets/test_data.csv\", keep_default_na=False, encoding='latin1')\n",
    "original_test_index = traffic_test.index.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567727b",
   "metadata": {},
   "source": [
    "**Data Treatment**\n",
    "\n",
    "Drop Columns:\n",
    "- city_name e Average Precipitation, porque é sempre o mesmo.\n",
    "- Average Cloudiness e Average Rain, porque tem muitos missing values.\n",
    "- Average Humidity, porque tem elevada correlação com Average Humidity.????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fe800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns \n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df.drop(columns=['city_name'], inplace=True)\n",
    "    df.drop(columns=['AVERAGE_PRECIPITATION'], inplace=True)\n",
    "    df.drop(columns=['AVERAGE_RAIN'], inplace=True)\n",
    "    df.drop(columns=['AVERAGE_CLOUDINESS'], inplace=True)\n",
    "    #df.drop(columns=['AVERAGE_HUMIDITY'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f007eb35",
   "metadata": {},
   "source": [
    "Feature Engeneering:\n",
    "- Partir a data em partes.\n",
    "- Colocar os dias com uma separação de semana e fim de semana.\n",
    "- is_weekend para identificar os dias que são fim de semana.\n",
    "- is_friday para identificar os dias que são sexta-feira.\n",
    "- is_holiday para identificar os dias que são feriados.\n",
    "- is_rush_hour para indentificar se é hora de ponta.\n",
    "- season para identificar a estação do ano correspondente.\n",
    "- daypart para identificar a parte do dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34f47187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Treatment\n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df['record_date'] = pd.to_datetime(df['record_date'])\n",
    "    \n",
    "    df['Year'] = df['record_date'].dt.year\n",
    "    df['Month'] = df['record_date'].dt.month\n",
    "    df['Hour'] = df['record_date'].dt.hour\n",
    "    \n",
    "    df['Day'] = df['record_date'].dt.dayofweek\n",
    "    #df['Day'] = df['record_date'].dt.day_name()\n",
    "    '''\n",
    "    df['Day'] = df['Day'].replace({\n",
    "        'Sunday': 1, 'Monday': 0, 'Tuesday': 0, 'Wednesday': 0,\n",
    "        'Thursday': 0, 'Friday': 0, 'Saturday': 1\n",
    "    }).astype(int) '''\n",
    "    \n",
    "    #df.drop(columns=['record_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1692090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "pt_holidays = holidays.Portugal()\n",
    "\n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df['is_weekend'] = df['record_date'].dt.weekday.isin([5, 6]).astype(int)\n",
    "    df['is_friday'] = (df['record_date'].dt.weekday == 4).astype(int)\n",
    "    df['is_holiday'] = df['record_date'].dt.date.map(lambda d: d in pt_holidays).astype(int)\n",
    "    df['is_rush_hour'] = ((df['Hour'] >= 7) & (df['Hour'] <= 9)) | ((df['Hour'] >= 17) & (df['Hour'] <= 19)).astype(int)\n",
    "    df['season'] = pd.cut(df['Month'], bins=[0, 3, 6, 9, 12], labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "    df.drop(columns=['record_date'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8885cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daypart(hour):\n",
    "    if hour > 0 and hour <= 8:\n",
    "        return \"dawn\"\n",
    "    elif hour > 8 and hour <= 16:\n",
    "        return \"working_hour\"\n",
    "    else: return \"midnight\"\n",
    "\n",
    "dfs = []\n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df_copy = df.copy()\n",
    "    df_copy['Day_Part'] = df_copy['Hour'].apply(daypart)\n",
    "    one_hot = pd.get_dummies(df_copy['Day_Part'])\n",
    "    df_copy = pd.concat([df_copy, one_hot], axis=1)\n",
    "    df_copy.drop('Day_Part', axis=1, inplace=True)\n",
    "    dfs.append(df_copy)\n",
    "\n",
    "traffic_train, traffic_test = dfs[0], dfs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341fd2ce",
   "metadata": {},
   "source": [
    "**Categorical Encoding**\n",
    "- Utilizado nas variáveis categóricas para transformar para numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afc7470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_6480\\3862299415.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  traffic_train['LUMINOSITY'] = traffic_train['LUMINOSITY'].replace(luminosity_map).astype(int)\n",
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_6480\\3862299415.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  traffic_test['LUMINOSITY'] = traffic_test['LUMINOSITY'].replace(luminosity_map).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Categorical Encoding\n",
    "speed_map = {'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High': 4}\n",
    "traffic_train['AVERAGE_SPEED_DIFF'] = traffic_train['AVERAGE_SPEED_DIFF'].map(speed_map).astype(int)\n",
    "\n",
    "luminosity_map = {'DARK': 0, 'LOW_LIGHT': 1, 'LIGHT': 2}\n",
    "traffic_train['LUMINOSITY'] = traffic_train['LUMINOSITY'].replace(luminosity_map).astype(int)\n",
    "traffic_test['LUMINOSITY'] = traffic_test['LUMINOSITY'].replace(luminosity_map).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c67777d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_6480\\52076908.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  traffic_train['season'] = traffic_train['season'].replace(season_map).astype(int)\n",
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_6480\\52076908.py:6: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  traffic_train['season'] = traffic_train['season'].replace(season_map).astype(int)\n",
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_6480\\52076908.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  traffic_test['season'] = traffic_test['season'].replace(season_map).astype(int)\n",
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_6480\\52076908.py:7: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  traffic_test['season'] = traffic_test['season'].replace(season_map).astype(int)\n"
     ]
    }
   ],
   "source": [
    "rush_hour_map = {'True': 1, 'False': 0}\n",
    "traffic_train['is_rush_hour'] = traffic_train['is_rush_hour'].replace(rush_hour_map).astype(int)\n",
    "traffic_test['is_rush_hour'] = traffic_test['is_rush_hour'].replace(rush_hour_map).astype(int)\n",
    "\n",
    "season_map = {'Winter': 0, 'Spring': 1, 'Summer': 2, 'Fall': 3}\n",
    "traffic_train['season'] = traffic_train['season'].replace(season_map).astype(int)\n",
    "traffic_test['season'] = traffic_test['season'].replace(season_map).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96993d",
   "metadata": {},
   "source": [
    "**Outliers Treatment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccc0bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Treatment\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df['AVERAGE_FREE_FLOW_TIME'] = winsorize(df['AVERAGE_FREE_FLOW_TIME'], limits=[0.01, 0.01])\n",
    "    df['AVERAGE_FREE_FLOW_SPEED'] = winsorize(df['AVERAGE_FREE_FLOW_SPEED'], limits=[0.05, 0.01])\n",
    "    df['AVERAGE_TEMPERATURE'] = winsorize(df['AVERAGE_TEMPERATURE'], limits=[0.01, 0.02])\n",
    "    df['AVERAGE_ATMOSP_PRESSURE'] = winsorize(df['AVERAGE_ATMOSP_PRESSURE'], limits=[0.05, 0.015])\n",
    "    df['AVERAGE_WIND_SPEED'] = winsorize(df['AVERAGE_WIND_SPEED'], limits=[0.01, 0.03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b59d2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier(s): \n",
    "    lower_limit = s.mean() - (s.std() * 1)\n",
    "    upper_limit = s.mean() + (s.std() * 1)\n",
    "    return ~s.between(lower_limit, upper_limit)\n",
    "\n",
    "outliers_train = traffic_train['AVERAGE_TIME_DIFF'].transform(is_outlier)\n",
    "outliers_test = traffic_test['AVERAGE_TIME_DIFF'].transform(is_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "878a6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = outliers_train == True\n",
    "\n",
    "train_com_outliers = traffic_train[mask]\n",
    "train_clean = traffic_train[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bf89e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = outliers_test == True\n",
    "\n",
    "test_com_outliers = traffic_test[mask]\n",
    "test_clean = traffic_test[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f480fcd",
   "metadata": {},
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f84f6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "X_s_outliers = train_clean.drop(['AVERAGE_SPEED_DIFF'], axis=1)\n",
    "y_s_outliers = train_clean['AVERAGE_SPEED_DIFF'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8935024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c_outliers = train_com_outliers.drop(['AVERAGE_SPEED_DIFF'], axis=1)\n",
    "y_c_outliers = train_com_outliers['AVERAGE_SPEED_DIFF'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d419425",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_semOutliers_final = X_s_outliers.to_numpy()\n",
    "y_semOutliers_final = y_s_outliers.to_numpy()\n",
    "\n",
    "X_c_outliers_final = X_c_outliers.to_numpy()\n",
    "y_c_outliers_final = y_c_outliers.to_numpy()\n",
    "\n",
    "teste_final_clean = test_clean.to_numpy()\n",
    "teste_final_com_outliers = test_com_outliers.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450110c4",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6803aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programas\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.31% (+/- 1.04%)\n"
     ]
    }
   ],
   "source": [
    "# Modeling\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "#outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_resampled, y_resampled = smote.fit_resample(X_c_outliers, y_c_outliers)\n",
    "\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "#model = RandomForestClassifier(random_state=2025, class_weight='balanced')\n",
    "model = RandomForestClassifier(random_state=2025)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 500],\n",
    "    'max_features': [2, 4, 6],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "res = grid_search.fit(X_s_outliers, np.ravel(y_s_outliers))\n",
    "#res = grid_search.fit(X_resampled, np.ravel(y_resampled))\n",
    "\n",
    "best_model = res.best_estimator_\n",
    "predictions_s_outliers = best_model.predict(teste_final_clean)\n",
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "scores = cross_val_score(grid_search, X_s_outliers, y_s_outliers, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "#scores = cross_val_score(grid_search, X_resampled, y_resampled, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "921e41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.28% (+/- 4.24%)\n"
     ]
    }
   ],
   "source": [
    "# Modeling\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "#outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_resampled, y_resampled = smote.fit_resample(X_c_outliers, y_c_outliers)\n",
    "\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "#model = RandomForestClassifier(random_state=2025, class_weight='balanced')\n",
    "model = RandomForestClassifier(random_state=2025)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 500],\n",
    "    'max_features': [2, 4, 6],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "res = grid_search.fit(X_c_outliers_final, np.ravel(y_c_outliers_final))\n",
    "#res = grid_search.fit(X_resampled, np.ravel(y_resampled))\n",
    "\n",
    "best_model = res.best_estimator_\n",
    "predictions_c_outliers = best_model.predict(teste_final_com_outliers)\n",
    "\n",
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "scores = cross_val_score(grid_search, X_c_outliers_final, y_c_outliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "#scores = cross_val_score(grid_search, X_resampled, y_resampled, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "189f511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissão criada: ../../submissions\\submission_21.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../submissions\\\\submission_21.csv'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_clean = pd.DataFrame({'Speed_Diff': predictions_s_outliers}, index=test_clean.index)\n",
    "pred_outliers = pd.DataFrame({'Speed_Diff': predictions_c_outliers}, index=test_com_outliers.index)\n",
    "\n",
    "final_predictions = pd.concat([pred_clean, pred_outliers])\n",
    "final_predictions = final_predictions.loc[original_test_index]\n",
    "\n",
    "speed_diff_mapping = {0: 'None', 1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very_High'}\n",
    "final_predictions['Speed_Diff'] = final_predictions['Speed_Diff'].map(speed_diff_mapping)\n",
    "\n",
    "create_submission_file(final_predictions,  prediction_col='Speed_Diff', filename='submission_21.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13804b",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a238a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'eval_metric': ['logloss', 'mlogloss', 'error']\n",
    "}\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "\n",
    "grid_search.fit(X_c_outliers_final, np.ravel(y_c_outliers_final))\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(teste_final_com_outliers)\n",
    "scores = cross_val_score(grid_search, X_c_outliers_final, y_c_outliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'eval_metric': ['logloss', 'mlogloss', 'error']\n",
    "}\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "\n",
    "grid_search.fit(X_semOutliers_final, np.ravel(y_semOutliers_final))\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(teste_final_clean)\n",
    "scores = cross_val_score(grid_search, X_semOutliers_final, y_semOutliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clean = pd.DataFrame({'Speed_Diff': predictions_s_outliers}, index=test_clean.index)\n",
    "pred_outliers = pd.DataFrame({'Speed_Diff': predictions_c_outliers}, index=test_com_outliers.index)\n",
    "\n",
    "final_predictions = pd.concat([pred_clean, pred_outliers])\n",
    "final_predictions = final_predictions.loc[original_test_index]\n",
    "\n",
    "speed_diff_mapping = {0: 'None', 1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very_High'}\n",
    "final_predictions['Speed_Diff'] = final_predictions['Speed_Diff'].map(speed_diff_mapping)\n",
    "\n",
    "create_submission_file(final_predictions,  prediction_col='Speed_Diff', filename='submission_19.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa17b0",
   "metadata": {},
   "source": [
    "**AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 2, 3]]\n",
    "}\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(ada_model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "\n",
    "grid_search.fit(X_semOutliers_final, np.ravel(y_semOutliers_final))\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(teste_final_clean)\n",
    "scores = cross_val_score(grid_search, X_semOutliers_final, y_semOutliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 2, 3]]\n",
    "}\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(ada_model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "\n",
    "grid_search.fit(X_c_outliers_final, np.ravel(y_c_outliers_final))\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(teste_final_com_outliers)\n",
    "scores = cross_val_score(grid_search, X_c_outliers_final, y_c_outliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clean = pd.DataFrame({'Speed_Diff': predictions_s_outliers}, index=test_clean.index)\n",
    "pred_outliers = pd.DataFrame({'Speed_Diff': predictions_c_outliers}, index=test_com_outliers.index)\n",
    "\n",
    "final_predictions = pd.concat([pred_clean, pred_outliers])\n",
    "final_predictions = final_predictions.loc[original_test_index]\n",
    "\n",
    "speed_diff_mapping = {0: 'None', 1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very_High'}\n",
    "final_predictions['Speed_Diff'] = final_predictions['Speed_Diff'].map(speed_diff_mapping)\n",
    "\n",
    "create_submission_file(final_predictions,  prediction_col='Speed_Diff', filename='submission_19.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
