{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.data_utils import load_datasets\n",
    "from utils.submission_utils import *\n",
    "import holidays\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "\n",
    "traffic_train = pd.read_csv(\"../../datasets/training_data.csv\", keep_default_na=False, encoding='latin1')\n",
    "traffic_test = pd.read_csv(\"../../datasets/test_data.csv\", keep_default_na=False, encoding='latin1')\n",
    "original_test_index = traffic_test.index.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0fc03",
   "metadata": {},
   "source": [
    "**Data Treatment**\n",
    "\n",
    "Drop Columns:\n",
    "- city_name e Average Precipitation, porque é sempre o mesmo.\n",
    "- Average Cloudiness e Average Rain, porque tem muitos missing values.\n",
    "- Average Humidity, porque tem elevada correlação com Average Humidity.????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fe800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns \n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df.drop(columns=['city_name'], inplace=True)\n",
    "    df.drop(columns=['AVERAGE_PRECIPITATION'], inplace=True)\n",
    "    df.drop(columns=['AVERAGE_RAIN'], inplace=True)\n",
    "    df.drop(columns=['AVERAGE_CLOUDINESS'], inplace=True)\n",
    "    #df.drop(columns=['AVERAGE_HUMIDITY'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb43cd4",
   "metadata": {},
   "source": [
    "Feature Engeneering:\n",
    "- Partir a data em partes.\n",
    "- Colocar os dias com uma separação de semana e fim de semana.\n",
    "- is_weekend para identificar os dias que são fim de semana.\n",
    "- is_friday para identificar os dias que são sexta-feira.\n",
    "- is_holiday para identificar os dias que são feriados.\n",
    "- is_rush_hour para indentificar se é hora de ponta.\n",
    "- season para identificar a estação do ano correspondente.\n",
    "- daypart para identificar a parte do dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f47187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Treatment\n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df['record_date'] = pd.to_datetime(df['record_date'])\n",
    "    \n",
    "    df['Year'] = df['record_date'].dt.year\n",
    "    df['Month'] = df['record_date'].dt.month\n",
    "    df['Hour'] = df['record_date'].dt.hour\n",
    "    \n",
    "    df['Day'] = df['record_date'].dt.dayofweek\n",
    "    #df['Day'] = df['record_date'].dt.day_name()\n",
    "    '''\n",
    "    df['Day'] = df['Day'].replace({\n",
    "        'Sunday': 1, 'Monday': 0, 'Tuesday': 0, 'Wednesday': 0,\n",
    "        'Thursday': 0, 'Friday': 0, 'Saturday': 1\n",
    "    }).astype(int) '''\n",
    "    \n",
    "    #df.drop(columns=['record_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1692090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "pt_holidays = holidays.Portugal()\n",
    "\n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df['is_weekend'] = df['record_date'].dt.weekday.isin([5, 6]).astype(int)\n",
    "    df['is_friday'] = (df['record_date'].dt.weekday == 4).astype(int)\n",
    "    df['is_holiday'] = df['record_date'].dt.date.map(lambda d: d in pt_holidays).astype(int)\n",
    "    df['is_rush_hour'] = ((df['Hour'] >= 7) & (df['Hour'] <= 9)) | ((df['Hour'] >= 17) & (df['Hour'] <= 19)).astype(int)\n",
    "    df['season'] = pd.cut(df['Month'], bins=[0, 3, 6, 9, 12], labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "    df.drop(columns=['record_date'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62149b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daypart(hour):\n",
    "    if hour > 0 and hour <= 8:\n",
    "        return \"dawn\"\n",
    "    elif hour > 8 and hour <= 16:\n",
    "        return \"working_hour\"\n",
    "    else: return \"midnight\"\n",
    "\n",
    "dfs = []\n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df_copy = df.copy()\n",
    "    df_copy['Day_Part'] = df_copy['Hour'].apply(daypart)\n",
    "    one_hot = pd.get_dummies(df_copy['Day_Part'])\n",
    "    df_copy = pd.concat([df_copy, one_hot], axis=1)\n",
    "    df_copy.drop('Day_Part', axis=1, inplace=True)\n",
    "    dfs.append(df_copy)\n",
    "\n",
    "traffic_train, traffic_test = dfs[0], dfs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8cb25",
   "metadata": {},
   "source": [
    "**Categorical Encoding**\n",
    "- Utilizado nas variáveis categóricas para transformar para numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Encoding\n",
    "speed_map = {'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High': 4}\n",
    "traffic_train['AVERAGE_SPEED_DIFF'] = traffic_train['AVERAGE_SPEED_DIFF'].map(speed_map).astype(int)\n",
    "\n",
    "luminosity_map = {'DARK': 0, 'LOW_LIGHT': 1, 'LIGHT': 2}\n",
    "traffic_train['LUMINOSITY'] = traffic_train['LUMINOSITY'].replace(luminosity_map).astype(int)\n",
    "traffic_test['LUMINOSITY'] = traffic_test['LUMINOSITY'].replace(luminosity_map).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efe102",
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_hour_map = {'True': 1, 'False': 0}\n",
    "traffic_train['is_rush_hour'] = traffic_train['is_rush_hour'].replace(rush_hour_map).astype(int)\n",
    "traffic_test['is_rush_hour'] = traffic_test['is_rush_hour'].replace(rush_hour_map).astype(int)\n",
    "\n",
    "season_map = {'Winter': 0, 'Spring': 1, 'Summer': 2, 'Fall': 3}\n",
    "traffic_train['season'] = traffic_train['season'].replace(season_map).astype(int)\n",
    "traffic_test['season'] = traffic_test['season'].replace(season_map).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab6514",
   "metadata": {},
   "source": [
    "**Outliers Treatment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00866bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Outliers By Average\n",
    "def replace(group):\n",
    "    mean, std = group.mean(), group.std()\n",
    "    outliers = (group - mean).abs() > 1*std\n",
    "    group[outliers] = mean        \n",
    "    return group\n",
    "\n",
    "traffic_train['AVERAGE_TIME_DIFF'] = traffic_train.groupby('AVERAGE_SPEED_DIFF')['AVERAGE_TIME_DIFF'].transform(replace)\n",
    "plt.subplots(figsize=(8,8))\n",
    "ax = sns.boxplot(x=traffic_train[\"AVERAGE_SPEED_DIFF\"], y=traffic_train[\"AVERAGE_TIME_DIFF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "traffic_train[['AVERAGE_FREE_FLOW_SPEED']] = min_max_scaler.fit_transform(traffic_train[['AVERAGE_FREE_FLOW_SPEED']])\n",
    "traffic_train[['AVERAGE_TIME_DIFF']] = min_max_scaler.fit_transform(traffic_train[['AVERAGE_TIME_DIFF']])\n",
    "traffic_train[['AVERAGE_FREE_FLOW_TIME']] = min_max_scaler.fit_transform(traffic_train[['AVERAGE_FREE_FLOW_TIME']])\n",
    "traffic_train['AVERAGE_TEMPERATURE'] = min_max_scaler.fit_transform(traffic_train[['AVERAGE_TEMPERATURE']])\n",
    "traffic_train[[\"AVERAGE_ATMOSP_PRESSURE\"]] = min_max_scaler.fit_transform(traffic_train[[\"AVERAGE_ATMOSP_PRESSURE\"]])\n",
    "traffic_train[[\"AVERAGE_WIND_SPEED\"]] = min_max_scaler.fit_transform(traffic_train[[\"AVERAGE_WIND_SPEED\"]])\n",
    "traffic_train[[\"hour\"]] = min_max_scaler.fit_transform(traffic_train[[\"hour\"]])\n",
    "traffic_train[[\"month\"]] = min_max_scaler.fit_transform(traffic_train[[\"month\"]])\n",
    "\n",
    "traffic_test[['AVERAGE_FREE_FLOW_SPEED']] = min_max_scaler.fit_transform(traffic_test[['AVERAGE_FREE_FLOW_SPEED']])\n",
    "traffic_test[['AVERAGE_TIME_DIFF']] = min_max_scaler.fit_transform(traffic_test[['AVERAGE_TIME_DIFF']])\n",
    "traffic_test[['AVERAGE_FREE_FLOW_TIME']] = min_max_scaler.fit_transform(traffic_test[['AVERAGE_FREE_FLOW_TIME']])\n",
    "traffic_test['AVERAGE_TEMPERATURE'] = min_max_scaler.fit_transform(traffic_test[['AVERAGE_TEMPERATURE']])\n",
    "traffic_test[[\"AVERAGE_ATMOSP_PRESSURE\"]] = min_max_scaler.fit_transform(traffic_test[[\"AVERAGE_ATMOSP_PRESSURE\"]])\n",
    "traffic_test[[\"AVERAGE_WIND_SPEED\"]] = min_max_scaler.fit_transform(traffic_test[[\"AVERAGE_WIND_SPEED\"]])\n",
    "traffic_test[[\"hour\"]] = min_max_scaler.fit_transform(traffic_test[[\"hour\"]])\n",
    "traffic_test[[\"month\"]] = min_max_scaler.fit_transform(traffic_test[[\"month\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier(s): \n",
    "    lower_limit = s.mean() - (s.std() * 1)\n",
    "    upper_limit = s.mean() + (s.std() * 1)\n",
    "    return ~s.between(lower_limit, upper_limit)\n",
    "\n",
    "outliers_train = traffic_train['AVERAGE_TIME_DIFF'].transform(is_outlier)\n",
    "outliers_test = traffic_test['AVERAGE_TIME_DIFF'].transform(is_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = outliers_train == True\n",
    "\n",
    "train_com_outliers = traffic_train[mask]\n",
    "train_clean = traffic_train[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = outliers_test == True\n",
    "\n",
    "test_com_outliers = traffic_test[mask]\n",
    "test_clean = traffic_test[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64098788",
   "metadata": {},
   "source": [
    "**Modeling**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "X_s_outliers = train_clean.drop(['AVERAGE_SPEED_DIFF'], axis=1)\n",
    "y_s_outliers = train_clean['AVERAGE_SPEED_DIFF'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c_outliers = train_com_outliers.drop(['AVERAGE_SPEED_DIFF'], axis=1)\n",
    "y_c_outliers = train_com_outliers['AVERAGE_SPEED_DIFF'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d419425",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_semOutliers_final = X_s_outliers.to_numpy()\n",
    "y_semOutliers_final = y_s_outliers.to_numpy()\n",
    "\n",
    "X_c_outliers_final = X_c_outliers.to_numpy()\n",
    "y_c_outliers_final = y_c_outliers.to_numpy()\n",
    "\n",
    "teste_final_clean = test_clean.to_numpy()\n",
    "teste_final_com_outliers = test_com_outliers.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450110c4",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6803aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "#outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_resampled, y_resampled = smote.fit_resample(X_c_outliers, y_c_outliers)\n",
    "\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "#model = RandomForestClassifier(random_state=2025, class_weight='balanced')\n",
    "model = RandomForestClassifier(random_state=2025)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 500],\n",
    "    'max_features': [2, 4, 6],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "res = grid_search.fit(X_s_outliers, np.ravel(y_s_outliers))\n",
    "#res = grid_search.fit(X_resampled, np.ravel(y_resampled))\n",
    "\n",
    "best_model = res.best_estimator_\n",
    "predictions_s_outliers = best_model.predict(teste_final_clean)\n",
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "scores = cross_val_score(grid_search, X_s_outliers, y_s_outliers, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "#scores = cross_val_score(grid_search, X_resampled, y_resampled, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "#outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_resampled, y_resampled = smote.fit_resample(X_c_outliers, y_c_outliers)\n",
    "\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "#model = RandomForestClassifier(random_state=2025, class_weight='balanced')\n",
    "model = RandomForestClassifier(random_state=2025)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 500],\n",
    "    'max_features': [2, 4, 6],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "res = grid_search.fit(X_c_outliers_final, np.ravel(y_c_outliers_final))\n",
    "#res = grid_search.fit(X_resampled, np.ravel(y_resampled))\n",
    "\n",
    "best_model = res.best_estimator_\n",
    "predictions_c_outliers = best_model.predict(teste_final_com_outliers)\n",
    "\n",
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "scores = cross_val_score(grid_search, X_c_outliers_final, y_c_outliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "#scores = cross_val_score(grid_search, X_resampled, y_resampled, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f74465",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clean = pd.DataFrame({'Speed_Diff': predictions_s_outliers}, index=test_clean.index)\n",
    "pred_outliers = pd.DataFrame({'Speed_Diff': predictions_c_outliers}, index=test_com_outliers.index)\n",
    "\n",
    "final_predictions = pd.concat([pred_clean, pred_outliers])\n",
    "final_predictions = final_predictions.loc[original_test_index]\n",
    "\n",
    "speed_diff_mapping = {0: 'None', 1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very_High'}\n",
    "final_predictions['Speed_Diff'] = final_predictions['Speed_Diff'].map(speed_diff_mapping)\n",
    "\n",
    "create_submission_file(final_predictions,  prediction_col='Speed_Diff', filename='submission_21.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13804b",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a238a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'eval_metric': ['logloss', 'mlogloss', 'error']\n",
    "}\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "\n",
    "grid_search.fit(X_c_outliers_final, np.ravel(y_c_outliers_final))\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(teste_final_com_outliers)\n",
    "scores = cross_val_score(grid_search, X_c_outliers_final, y_c_outliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b2534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'eval_metric': ['logloss', 'mlogloss', 'error']\n",
    "}\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "\n",
    "grid_search.fit(X_semOutliers_final, np.ravel(y_semOutliers_final))\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(teste_final_clean)\n",
    "scores = cross_val_score(grid_search, X_semOutliers_final, y_semOutliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dcabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clean = pd.DataFrame({'Speed_Diff': predictions_s_outliers}, index=test_clean.index)\n",
    "pred_outliers = pd.DataFrame({'Speed_Diff': predictions_c_outliers}, index=test_com_outliers.index)\n",
    "\n",
    "final_predictions = pd.concat([pred_clean, pred_outliers])\n",
    "final_predictions = final_predictions.loc[original_test_index]\n",
    "\n",
    "speed_diff_mapping = {0: 'None', 1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very_High'}\n",
    "final_predictions['Speed_Diff'] = final_predictions['Speed_Diff'].map(speed_diff_mapping)\n",
    "\n",
    "create_submission_file(final_predictions,  prediction_col='Speed_Diff', filename='submission_19.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa17b0",
   "metadata": {},
   "source": [
    "**AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 2, 3]]\n",
    "}\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(ada_model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "\n",
    "grid_search.fit(X_semOutliers_final, np.ravel(y_semOutliers_final))\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(teste_final_clean)\n",
    "scores = cross_val_score(grid_search, X_semOutliers_final, y_semOutliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 2, 3]]\n",
    "}\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(ada_model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "\n",
    "grid_search.fit(X_c_outliers_final, np.ravel(y_c_outliers_final))\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(teste_final_com_outliers)\n",
    "scores = cross_val_score(grid_search, X_c_outliers_final, y_c_outliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b523272",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clean = pd.DataFrame({'Speed_Diff': predictions_s_outliers}, index=test_clean.index)\n",
    "pred_outliers = pd.DataFrame({'Speed_Diff': predictions_c_outliers}, index=test_com_outliers.index)\n",
    "\n",
    "final_predictions = pd.concat([pred_clean, pred_outliers])\n",
    "final_predictions = final_predictions.loc[original_test_index]\n",
    "\n",
    "speed_diff_mapping = {0: 'None', 1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very_High'}\n",
    "final_predictions['Speed_Diff'] = final_predictions['Speed_Diff'].map(speed_diff_mapping)\n",
    "\n",
    "create_submission_file(final_predictions,  prediction_col='Speed_Diff', filename='submission_19.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
