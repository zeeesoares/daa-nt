{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bbf731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.data_utils import load_datasets\n",
    "from utils.submission_utils import *\n",
    "import holidays\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "traffic_train = pd.read_csv(\"../../datasets/training_data.csv\", keep_default_na=False, encoding='latin1')\n",
    "traffic_test = pd.read_csv(\"../../datasets/test_data.csv\", keep_default_na=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef52e0ae",
   "metadata": {},
   "source": [
    "**Data Preparation**\n",
    "\n",
    "Remoção de colunas não necessárias:\n",
    "- city_name e AVERAGE_PRECIPITATION porque é só um valor.\n",
    "- AVERAGE_CLOUDINESS por causa dos missing values.\n",
    "- AVERAGE_RAIN por causa dos missing values.\n",
    "- AVERAGE_HUMIDITY tem grande correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e267366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns \n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df.drop(columns=['city_name'], inplace=True)\n",
    "    df.drop(columns=['AVERAGE_PRECIPITATION'], inplace=True)\n",
    "    df.drop(columns=['AVERAGE_RAIN'], inplace=True)\n",
    "    df.drop(columns=['AVERAGE_CLOUDINESS'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34752f",
   "metadata": {},
   "source": [
    "Extração de campos do atributo da data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4004659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Treatment\n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df['record_date'] = pd.to_datetime(df['record_date'])\n",
    "    df['hour'] = df['record_date'].dt.hour\n",
    "    df['day_of_week'] = df['record_date'].dt.dayofweek\n",
    "    df['month'] = df['record_date'].dt.month\n",
    "    df['year'] = df['record_date'].dt.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2247f9d",
   "metadata": {},
   "source": [
    "**Feature Engineering:**\n",
    "\n",
    "Criação de features para acrescentar valores e atributos ao dataset:\n",
    "- is_weekend por causa do fim de semana.\n",
    "- is_friday por causa de ser sexta-feira.\n",
    "- is_holiday por causa de ser feriado.\n",
    "- is_rush_hour por causa das horas de ponta.\n",
    "- season por causa da estação do ano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03ae4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "pt_holidays = holidays.Portugal()\n",
    "\n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df['is_weekend'] = df['record_date'].dt.weekday.isin([5, 6]).astype(int)\n",
    "    df['is_friday'] = (df['record_date'].dt.weekday == 4).astype(int)\n",
    "    df['is_holiday'] = df['record_date'].dt.date.map(lambda d: d in pt_holidays).astype(int)\n",
    "    df['is_rush_hour'] = ((df['hour'] >= 7) & (df['hour'] <= 9)) | ((df['hour'] >= 17) & (df['hour'] <= 19)).astype(int)\n",
    "    df['season'] = pd.cut(df['month'], bins=[0, 3, 6, 9, 12], labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "    df.drop(columns=['record_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d585822",
   "metadata": {},
   "source": [
    "**Categorical Encoding**\n",
    "\n",
    "Fazer enconding de todas as features categóricas para poder trabalhar com os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f7290d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_map = {'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High': 4}\n",
    "traffic_train['AVERAGE_SPEED_DIFF'] = traffic_train['AVERAGE_SPEED_DIFF'].map(speed_map).astype(int)\n",
    "\n",
    "rush_hour_map = {'True': 1, 'False': 0}\n",
    "traffic_train['is_rush_hour'] = traffic_train['is_rush_hour'].replace(rush_hour_map).astype(int)\n",
    "traffic_test['is_rush_hour'] = traffic_test['is_rush_hour'].replace(rush_hour_map).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b2b687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_15732\\271531659.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  traffic_train['LUMINOSITY'] = traffic_train['LUMINOSITY'].replace(luminosity_map).astype(int)\n",
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_15732\\271531659.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  traffic_test['LUMINOSITY'] = traffic_test['LUMINOSITY'].replace(luminosity_map).astype(int)\n",
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_15732\\271531659.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  traffic_train['season'] = traffic_train['season'].replace(season_map).astype(int)\n",
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_15732\\271531659.py:15: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  traffic_train['season'] = traffic_train['season'].replace(season_map).astype(int)\n",
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_15732\\271531659.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  traffic_test['season'] = traffic_test['season'].replace(season_map).astype(int)\n",
      "C:\\Users\\rodme\\AppData\\Local\\Temp\\ipykernel_15732\\271531659.py:16: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  traffic_test['season'] = traffic_test['season'].replace(season_map).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Categorical Encoding\n",
    "\n",
    "speed_map = {'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High': 4}\n",
    "traffic_train['AVERAGE_SPEED_DIFF'] = traffic_train['AVERAGE_SPEED_DIFF'].map(speed_map).astype(int)\n",
    "\n",
    "luminosity_map = {'DARK': 0, 'LOW_LIGHT': 1, 'LIGHT': 2}\n",
    "traffic_train['LUMINOSITY'] = traffic_train['LUMINOSITY'].replace(luminosity_map).astype(int)\n",
    "traffic_test['LUMINOSITY'] = traffic_test['LUMINOSITY'].replace(luminosity_map).astype(int)\n",
    "\n",
    "rush_hour_map = {'True': 1, 'False': 0}\n",
    "traffic_train['is_rush_hour'] = traffic_train['is_rush_hour'].replace(rush_hour_map).astype(int)\n",
    "traffic_test['is_rush_hour'] = traffic_test['is_rush_hour'].replace(rush_hour_map).astype(int)\n",
    "\n",
    "season_map = {'Winter': 0, 'Spring': 1, 'Summer': 2, 'Fall': 3}\n",
    "traffic_train['season'] = traffic_train['season'].replace(season_map).astype(int)\n",
    "traffic_test['season'] = traffic_test['season'].replace(season_map).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f09a68",
   "metadata": {},
   "source": [
    "**Tratamento de Outliers**\n",
    " -> Aqui faz-se uma substituição dos outliers pelos valores mais próximos permitidos em termos de percentis divisão.\n",
    "\n",
    "**A fazer (testar combinações)**\n",
    "- Gráficos de caixas de bigodes no dataPreparation para ver os outliers.\n",
    "- Substituir outliers pela média ou assim e normalizar.\n",
    "- Fazer só com outliers sem winsorize.\n",
    "- Quantis puros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b905b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Treatment\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "for df in [traffic_train, traffic_test]:\n",
    "    df['AVERAGE_FREE_FLOW_TIME'] = winsorize(df['AVERAGE_FREE_FLOW_TIME'], limits=[0.01, 0.01])\n",
    "    df['AVERAGE_FREE_FLOW_SPEED'] = winsorize(df['AVERAGE_FREE_FLOW_SPEED'], limits=[0.05, 0.01])\n",
    "    df['AVERAGE_TEMPERATURE'] = winsorize(df['AVERAGE_TEMPERATURE'], limits=[0.01, 0.02])\n",
    "    df['AVERAGE_ATMOSP_PRESSURE'] = winsorize(df['AVERAGE_ATMOSP_PRESSURE'], limits=[0.05, 0.015])\n",
    "    df['AVERAGE_WIND_SPEED'] = winsorize(df['AVERAGE_WIND_SPEED'], limits=[0.01, 0.03])\n",
    "    df['AVERAGE_HUMIDITY'] = winsorize(df['AVERAGE_HUMIDITY'], limits=[0.03, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "710ba397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier(s): \n",
    "    lower_limit = s.mean() - s.std()\n",
    "    upper_limit = s.mean() + s.std()\n",
    "    return ~s.between(lower_limit, upper_limit)\n",
    "\n",
    "outliers_train = traffic_train['AVERAGE_TIME_DIFF'].transform(is_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02dd1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~traffic_train['AVERAGE_TIME_DIFF'].transform(is_outlier)\n",
    "\n",
    "train_com_outliers = traffic_train\n",
    "train_clean = traffic_train[~outliers_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0bf33b",
   "metadata": {},
   "source": [
    "**Modeling**\n",
    "\n",
    "Modelação com ambos os datasets com tratamento de outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44193dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "X = train_clean.drop(['AVERAGE_SPEED_DIFF'], axis=1)\n",
    "y = train_clean['AVERAGE_SPEED_DIFF'].to_frame()\n",
    "\n",
    "X_c_outliers = train_com_outliers.drop(['AVERAGE_SPEED_DIFF'], axis=1)\n",
    "y_c_outliers = train_com_outliers['AVERAGE_SPEED_DIFF'].to_frame()\n",
    "\n",
    "features = X_c_outliers.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e890fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino_final = X.to_numpy()\n",
    "y_treino_final = y.to_numpy()\n",
    "\n",
    "X_c_outliers_final = X_c_outliers.to_numpy()\n",
    "y_c_outliers_final = y_c_outliers.to_numpy()\n",
    "\n",
    "teste_final_clean = traffic_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531b289",
   "metadata": {},
   "source": [
    "**Random Forest com cross validation**\n",
    "\n",
    "**A fazer**\n",
    "- Stratified Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bcb2fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'eval_metric': 'logloss', 'max_depth': 3, 'n_estimators': 100}\n",
      "Best cross-validated accuracy: 0.8067\n",
      "Accuracy: 80.39% (+/- 1.11%)\n",
      "Submissão criada: ../../submissions\\submission_63.csv\n",
      "                    feature  importance\n",
      "1         AVERAGE_TIME_DIFF    0.468327\n",
      "0   AVERAGE_FREE_FLOW_SPEED    0.089290\n",
      "15             is_rush_hour    0.061555\n",
      "8                      hour    0.061295\n",
      "2    AVERAGE_FREE_FLOW_TIME    0.041677\n",
      "9               day_of_week    0.041572\n",
      "10                    month    0.036578\n",
      "3                LUMINOSITY    0.034586\n",
      "11                     year    0.031465\n",
      "4       AVERAGE_TEMPERATURE    0.028366\n",
      "6          AVERAGE_HUMIDITY    0.024976\n",
      "13                is_friday    0.023614\n",
      "7        AVERAGE_WIND_SPEED    0.021983\n",
      "5   AVERAGE_ATMOSP_PRESSURE    0.019122\n",
      "14               is_holiday    0.015595\n",
      "12               is_weekend    0.000000\n",
      "16                   season    0.000000\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'eval_metric': ['logloss', 'mlogloss', 'error'],\n",
    "}\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "\n",
    "grid_search.fit(X_c_outliers_final, np.ravel(y_c_outliers_final))\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(teste_final_clean)\n",
    "scores = cross_val_score(grid_search, X_c_outliers_final, y_c_outliers_final, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))\n",
    "\n",
    "teste_final_clean['Speed_Diff'] = predictions\n",
    "teste_final_clean['Speed_Diff'] = teste_final_clean['Speed_Diff'].map({0: 'None', 1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very_High'})\n",
    "\n",
    "\n",
    "create_submission_file(teste_final_clean,  prediction_col='Speed_Diff', filename='submission_63.csv')\n",
    "\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(feature_importances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
